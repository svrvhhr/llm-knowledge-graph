import json
import os
import streamlit as st

from app.config.loader import load_config
from app.pipeline.run import process_text_in_chunks
from app.visualization.visualizer import visualize_knowledge_graph

st.set_page_config(
    page_title="LLM Knowledge Graph",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üß† LLM Knowledge Graph Generator")
st.caption("Upload un texte ‚Üí extraction (LLM) ‚Üí standardisation ‚Üí inf√©rence ‚Üí visualisation interactive")

# ---------------- Sidebar ----------------
st.sidebar.header("‚öôÔ∏è Param√®tres")

config_path = st.sidebar.text_input("Chemin config.toml", "config.toml")
output_html = st.sidebar.text_input("Sortie HTML", "storage/outputs/knowledge_graph.html")

debug = st.sidebar.checkbox("Debug (LLM raw)", value=False)
disable_std = st.sidebar.checkbox("D√©sactiver standardisation", value=False)
disable_inf = st.sidebar.checkbox("D√©sactiver inf√©rence", value=False)

st.sidebar.markdown("---")
st.sidebar.info("Astuce : mets tes fichiers .txt dans `storage/inputs/`")

config = load_config(config_path)
if not config:
    st.error("‚ùå Impossible de charger config.toml. V√©rifie le chemin.")
    st.stop()

# override config depuis UI
if disable_std:
    config.setdefault("standardization", {})["enabled"] = False
if disable_inf:
    config.setdefault("inference", {})["enabled"] = False

# ---------------- Main input area ----------------
colA, colB = st.columns([1.1, 1])

with colA:
    st.subheader("üìÑ Entr√©e")
    uploaded = st.file_uploader("Fichier .txt", type=["txt"])
    text_area = st.text_area("Ou colle ton texte ici", height=220, placeholder="Colle ton texte‚Ä¶")

with colB:
    st.subheader("üöÄ Lancer")
    st.write("Clique pour g√©n√©rer le graphe.")
    run = st.button("G√©n√©rer le graphe", use_container_width=True)

# ---------------- Run pipeline ----------------
if run:
    if uploaded is not None:
        input_text = uploaded.read().decode("utf-8", errors="ignore")
    else:
        input_text = text_area.strip()

    if not input_text:
        st.warning("‚ö†Ô∏è Ajoute un texte ou upload un fichier.")
        st.stop()

    with st.spinner("Extraction et construction du graphe en cours‚Ä¶"):
        triples = process_text_in_chunks(config, input_text, debug=debug)

    if not triples:
        st.error("‚ùå Aucun triplet extrait. V√©rifie ton texte ou ton endpoint LLM.")
        st.stop()

    # save JSON next to HTML
    os.makedirs(os.path.dirname(output_html), exist_ok=True)
    json_path = output_html.replace(".html", ".json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(triples, f, indent=2, ensure_ascii=False)

    stats = visualize_knowledge_graph(triples, output_html, config=config)

    # ---------------- Results ----------------
    st.success("‚úÖ Graphe g√©n√©r√© avec succ√®s")

    s1, s2, s3, s4 = st.columns(4)
    s1.metric("N≈ìuds", stats.get("nodes", 0))
    s2.metric("Ar√™tes", stats.get("edges", 0))
    s3.metric("Inf√©r√©es", stats.get("inferred_edges", 0))
    s4.metric("Communaut√©s", stats.get("communities", 0))

    st.subheader("üï∏Ô∏è Visualisation")
    html = open(output_html, "r", encoding="utf-8").read()
    st.components.v1.html(html, height=780, scrolling=True)

    with st.expander("üì¶ Voir les triplets (JSON)"):
        st.json(triples)

    st.download_button(
        "T√©l√©charger le JSON",
        data=json.dumps(triples, ensure_ascii=False, indent=2).encode("utf-8"),
        file_name=os.path.basename(json_path),
        mime="application/json",
        use_container_width=True
    )
